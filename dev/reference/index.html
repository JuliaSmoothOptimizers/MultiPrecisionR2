<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · MultiPrecisionR2.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="/reference/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="MultiPrecisionR2.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MultiPrecisionR2.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li><li><a class="tocitem" href="../MPCounters/">MPCounters</a></li><li><a class="tocitem" href="../FPMPNLPModel/">FPMPNLPModel</a></li><li><a class="tocitem" href="../MultiPrecisionR2/">MultiPrecisionR2</a></li><li><a class="tocitem" href="../tutorial_FPMPNLPModel/">FPMPNLPModel Tutorial</a></li><li><a class="tocitem" href="../tutorial_MPR2_basic_use/">MPR2 Tutorial: Basic Use </a></li><li><a class="tocitem" href="../tutorial_MPR2_advanced_use/">MPR2 Tutorial: Advanced Use </a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><p>​</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><p>​</p><ul><li><a href="#Reference">Reference</a></li><li class="no-marker"><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></li></ul><p>​</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p>​</p><ul><li><a href="#MultiPrecisionR2.FPMPNLPModel"><code>MultiPrecisionR2.FPMPNLPModel</code></a></li><li><a href="#MultiPrecisionR2.MPCounters"><code>MultiPrecisionR2.MPCounters</code></a></li><li><a href="#MultiPrecisionR2.MPR2Params"><code>MultiPrecisionR2.MPR2Params</code></a></li><li><a href="#MultiPrecisionR2.MPR2Precisions-Tuple{Int64}"><code>MultiPrecisionR2.MPR2Precisions</code></a></li><li><a href="#MultiPrecisionR2.MPR2Precisions"><code>MultiPrecisionR2.MPR2Precisions</code></a></li><li><a href="#MultiPrecisionR2.MPR2Solver"><code>MultiPrecisionR2.MPR2Solver</code></a></li><li><a href="#MultiPrecisionR2.CheckMPR2ParamConditions-Tuple{MPR2Params}"><code>MultiPrecisionR2.CheckMPR2ParamConditions</code></a></li><li><a href="#MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradIntervalEval_test</code></a></li><li><a href="#MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradTypeStableTest</code></a></li><li><a href="#MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}"><code>MultiPrecisionR2.MPR2</code></a></li><li><a href="#MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjIntervalEval_test</code></a></li><li><a href="#MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjTypeStableTest</code></a></li><li><a href="#MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}"><code>MultiPrecisionR2.check_overflow</code></a></li><li><a href="#MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple"><code>MultiPrecisionR2.computeCandidate!</code></a></li><li><a href="#MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}"><code>MultiPrecisionR2.computeModelDecrease!</code></a></li><li><a href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>MultiPrecisionR2.computeMu</code></a></li><li><a href="#MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.computeStep!</code></a></li><li><a href="#MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_c_default!</code></a></li><li><a href="#MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_x_default!</code></a></li><li><a href="#MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_g_default!</code></a></li><li><a href="#MultiPrecisionR2.get_id-Tuple{FPMPNLPModel, DataType}"><code>MultiPrecisionR2.get_id</code></a></li><li><a href="#MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec</code></a></li><li><a href="#MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec!</code></a></li><li><a href="#MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp</code></a></li><li><a href="#MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp!</code></a></li><li><a href="#MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}"><code>MultiPrecisionR2.increment!</code></a></li><li><a href="#MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.objReachPrec</code></a></li><li><a href="#MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S"><code>MultiPrecisionR2.objerrmp</code></a></li><li><a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.recomputeMu!</code></a></li><li><a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>MultiPrecisionR2.recomputeMuPrecSelection!</code></a></li><li><a href="#MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.recompute_g_default!</code></a></li><li><a href="#MultiPrecisionR2.reset!-Tuple{MPCounters}"><code>MultiPrecisionR2.reset!</code></a></li><li><a href="#MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.reset!</code></a></li><li><a href="#MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}"><code>MultiPrecisionR2.selectPic_default!</code></a></li><li><a href="#MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}"><code>MultiPrecisionR2.selectPif!</code></a></li><li><a href="#MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.sum_counters</code></a></li><li><a href="#MultiPrecisionR2.sum_counters-Tuple{MPCounters}"><code>MultiPrecisionR2.sum_counters</code></a></li><li><a href="#MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S"><code>MultiPrecisionR2.umpt!</code></a></li><li><a href="#MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}"><code>MultiPrecisionR2.update_struct!</code></a></li><li><a href="#MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}"><code>MultiPrecisionR2.γfunc_test_error_bound</code></a></li><li><a href="#MultiPrecisionR2.γfunc_test_template-Tuple{Any}"><code>MultiPrecisionR2.γfunc_test_template</code></a></li><li><a href="#NLPModels.neval_cons-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons</code></a></li><li><a href="#NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_lin</code></a></li><li><a href="#NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_nln</code></a></li><li><a href="#NLPModels.neval_grad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_grad</code></a></li><li><a href="#NLPModels.neval_hess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hess</code></a></li><li><a href="#NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hprod</code></a></li><li><a href="#NLPModels.neval_jac-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac</code></a></li><li><a href="#NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_lin</code></a></li><li><a href="#NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_nln</code></a></li><li><a href="#NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jcon</code></a></li><li><a href="#NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jgrad</code></a></li><li><a href="#NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhess</code></a></li><li><a href="#NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhprod</code></a></li><li><a href="#NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod</code></a></li><li><a href="#NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_lin</code></a></li><li><a href="#NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_nln</code></a></li><li><a href="#NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod</code></a></li><li><a href="#NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_lin</code></a></li><li><a href="#NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_nln</code></a></li><li><a href="#NLPModels.neval_obj-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_obj</code></a></li></ul><p>​</p><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.FPMPNLPModel" href="#MultiPrecisionR2.FPMPNLPModel"><code>MultiPrecisionR2.FPMPNLPModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FPMPNLPModel(Model::AbstractNLPModel{D,S},FPList::Vector{K}; kwargs...) where {D,S,K&lt;:DataType}
FPMPNLPModel(f,x0, FPList::Vector{DataType}; kwargs...)</code></pre><p>Floating-Point Multi-Precision Non Linear Model (<code>FPMPNLPModel</code>) structure. This structure is intended to extend <code>NLPModel</code> structure to multi-precision.</p><p>Provides errors on objective function and grandient evaluation (see <code>objerrmp</code> and <code>graderrmp</code>).</p><p>The error models are :</p><ul><li>ojective: |fl(f(x)) - f(x)| ≤ ωf</li><li>gradient: ||fl(∇f(x)) - ∇f(x)||₂ ≤ ||fl(∇f(x))||₂ ωg.</li></ul><p>ωf and ωg are evaluated either using:</p><ul><li>interval analysis (can be very slow)</li><li>based on relative error assumption (see <code>ωfRelErr</code> and <code>ωgRelErr</code> field description below)   </li></ul><p><strong>Fields</strong></p><ul><li><code>Model::AbstractNLPModel</code> : NLPModel</li><li><code>FPList::Vector{DataType}</code> : List of floating point formats</li><li><code>EpsList::Vector{H}</code> : List of machine epsilons of the floating point formats in <code>FPList</code></li><li><code>UList::Vector{H}</code> : List of unit round-off of the floating point formats in <code>FPList</code></li><li><code>γfunc</code> : callback function for dot product rounding error parameter |γ|, |fl(x.y) - x.y| ≤ |x|.|y| γ. Expected signature is <code>γfunc(n::Int,u::H)</code> and output is <code>H</code>. Default callback <code>γfunc(n::Int,u::H) = n*u</code> is implemented upon instantiation. </li><li><code>ωfRelErr::Vector{H}</code> : List of relative error factor for objective function evaluation for formats in <code>FPList</code>. Error model is |f(x)-fl(f(x))| ≤ ωfRelErr * |fl(f(x))| </li><li><code>ωgRelErr::Vector{H}</code> : List of relative error factor for gradient evaluation for formats in <code>FPList</code>. Error model is ||∇f(x)-fl(∇f(x))||₂ ≤ ωgRelErr * ||fl(∇f(x))||₂ </li><li><code>ObjEvalMode::Int</code> : Evalutation mode for objective and error. Set automatically upon instantiation. Possible values:<ul><li><code>INT_ERR</code> : interval evaluation of objective (chosen as middle of the interval) and error</li><li><code>REL_ERR</code> : classical evaluation and use relative error model (with <code>ωfRelErr</code> value)</li></ul></li><li><code>GradEvalMode::Int</code> : Evalutation mode for gradient and error. Set automatically upon instantiation. Possible values:<ul><li><code>INT_ERR</code> : interval evaluation of gradient (chosen as middle of interval vector) and error</li><li><code>REL_ERR</code> : classical evaluation and use relative error model (with <code>ωgRelErr</code> value)</li></ul></li></ul><p><strong>Constructors:</strong></p><ul><li><p><code>FPMPModel(Model, FPList; kwargs...)</code> :</p><ul><li><code>Model::AbstractNLPModel</code>: Base model</li><li><code>FPList::Vector{DataType}</code>: List of FP formats that can be used for evaluations</li></ul></li><li><p><code>FPModels(f,x0::Vector,FPList::Vector{DataType}; kwargs...)</code> : Instanciate a <code>ADNLPModel</code> with <code>f</code> and <code>x0</code> and call above constructor</p><ul><li><code>f</code> : objective function</li><li><code>x0</code> : initial solution</li><li><code>FPList::Vector{DataType}</code>: List of FP formats that can be used for evaluations</li></ul></li></ul><p><strong>Keyword arguments:</strong></p><ul><li><code>HPFormat=Float64</code> : high precision format (must be at least as accurate as FPList[end])</li><li><code>γfunc=nothing</code> : use default if not provided (see Fields section above)</li><li><code>ωfRelErr=HPFormat.(sqrt.(eps.(FPList)))</code>: use relative error model by default for objective evaluation</li><li><code>ωgRelErr=HPFormat.(sqrt.(eps.(FPList)))</code>: use relative error model by default for gradient evaluation</li><li><code>obj_int_eval = false</code> : if true, use interval arithmetic for objective value and error evaluation</li><li><code>grad_int_eval = false</code> : if true, use interval arithmetic for gradient value and error evaluation</li></ul><p><strong>Checks upon instantiation</strong></p><p>Some checks are performed upon instantiation. These checks include:</p><ul><li>Length consistency of vector fields:  FPList, EpsList</li><li>HPFormat is at least as accurate as the highest precision floating point format in <code>FPList</code>. Ideally HPFormat is more accurate to ensure the numerical stability of MPR2 algorithm.</li><li>Interval evaluations: it might happen that interval evaluation of objective function and/or gradient is type-unstable or returns an error. The constructor returns an error in this case. This type of error is most likely due to <code>IntervalArithmetic.jl</code>.</li><li>FPList is ordered by increasing floating point format accuracy</li></ul><p>These checks can return <code>@warn</code> or <code>error</code>. </p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using MultiPrecisionR2

T = [Float16, Float32]
f(x) = x[1]^2 + x[2]^2
x = zeros(2)
mpnlp = FPMPNLPModel(f,x0,T)</code></pre><hr/><pre><code class="language-julia hljs">using MultiPrecisionR2
using OptimizationProblems
using OptimizationProblems.ADNLPProblems
using ADNLPModels
using BFloat16s

T = [BFloat16, Float16, Float32]
nlp = woods()
mpnlp = (nlp,T)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPCounters" href="#MultiPrecisionR2.MPCounters"><code>MultiPrecisionR2.MPCounters</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPCounters</code></pre><p>Struct for storing the number of function evaluations with each floating point format. The fields are the same as <a href="https://jso.dev/NLPModels.jl/stable/reference/#NLPModels.Counters">NLPModels.Counters</a>, but are <code>Dict{DataType,Int}</code> instead of <code>Int</code>.</p><hr/><pre><code class="nohighlight hljs">MPCounters(FPformats::Vector{DataType})</code></pre><p>Creates an empty MPCounters struct for types in the vector <code>FPformats</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">using MultiPrecisionR2.jl
FPformats = [Float16, Float32]
cntrs = MPCounters(FPformats)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Params" href="#MultiPrecisionR2.MPR2Params"><code>MultiPrecisionR2.MPR2Params</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPR2Params(LPFormat::DataType, HPFormat::DataType)</code></pre><p>MPR2 parameters structure.</p><p><strong>Fields</strong></p><ul><li><code>η₀::H</code> : controls objective function error tolerance, convergence condition is ωf ≤ η₀ ΔT (see <code>FPMPNLPModel</code> for details on ωf)</li><li><code>η₁::H</code> : step successful if ρ ≥ η₁ (update incumbent)</li><li><code>η₂::H</code> : step very successful if ρ ≥ η₂ (decrease σ ⟹ increase step length)</li><li><code>κₘ::H</code> : tolerance on gradient evaluation error, μ ≤ κₘ (see <code>computeMu</code>) </li><li><code>γ₁::L</code> : σk+1 = σk * γ₁ if ρ ≥ η₂</li><li><code>γ₂::L</code> : σk+1 = σk * γ₂ if ρ &lt; η₁</li></ul><p><strong>Parameters</strong></p><ul><li><code>H</code> must correspond to <code>MPnlp.HPFormat</code> with <code>MPnlp</code> given as input of <code>MPR2</code></li><li><code>L</code> must correspond to <code>MPnlp.FPList[1]</code>, i.e the lowest precision floating point format used by <code>MPnlp</code> given as input of <code>MPR2</code></li></ul><p><strong>Conditions</strong></p><p>Parameters must statisfy the following conditions:</p><ul><li>0 ≤ η₀ ≤ 1/2*η₁</li><li>0 ≤ η₁ ≤ η₂ &lt; 1</li><li>η₀+κₘ/2 ≤0.5*(1-η₂)</li><li>η₂&lt;1 </li><li>0&lt;γ₁&lt;1&lt;γ₂</li></ul><p>Instiates default values:</p><ul><li><code>η₀::H = 0.01</code></li><li><code>η₁::H = 0.02</code></li><li><code>η₂::H = 0.95</code></li><li><code>κₘ::H = 0.02</code> </li><li><code>γ₁::L = 2^(-2)</code></li><li><code>γ₂::L = 2</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Precisions" href="#MultiPrecisionR2.MPR2Precisions"><code>MultiPrecisionR2.MPR2Precisions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPR2Precisions(π::Int)</code></pre><p>FP format index storage structure.</p><p>Stores FP formats index in <code>FPMPNLPModel.FPList</code> of obj, grad, model reduction and norms evaluations, and FP format index of MPR2 algorithm vector variables. </p><p><strong>Fields</strong></p><ul><li><code>πx::Int</code> : Current FP format of current incumbent <code>x</code></li><li><code>πnx::Int</code> : FP format used for <code>x</code> norm evaluation</li><li><code>πs::Int</code> : Current FP format of step<code>s</code></li><li><code>πns::Int</code> : FP format used for <code>s</code> norm evaluation</li><li><code>πc::Int</code> : Current FP format of candidate <code>c</code></li><li><code>πf::Int</code> : FP format used for objective evaluation at <code>x</code></li><li><code>πf⁺::Int</code> : FP format used for objective evaluation at <code>c</code></li><li><code>πg::Int</code> : FP format used for gradient evaluation at <code>c</code></li><li><code>πΔ::Int</code> : FP format used for model reduction computation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Precisions-Tuple{Int64}" href="#MultiPrecisionR2.MPR2Precisions-Tuple{Int64}"><code>MultiPrecisionR2.MPR2Precisions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MPR2Precisions(π::Int)</code></pre><p>FP format index storage structure.</p><p>Stores FP formats index in <code>FPMPNLPModel.FPList</code> of obj, grad, model reduction and norms evaluations, and FP format index of MPR2 algorithm vector variables. </p><p><strong>Fields</strong></p><ul><li><code>πx::Int</code> : Current FP format of current incumbent <code>x</code></li><li><code>πnx::Int</code> : FP format used for <code>x</code> norm evaluation</li><li><code>πs::Int</code> : Current FP format of step<code>s</code></li><li><code>πns::Int</code> : FP format used for <code>s</code> norm evaluation</li><li><code>πc::Int</code> : Current FP format of candidate <code>c</code></li><li><code>πf::Int</code> : FP format used for objective evaluation at <code>x</code></li><li><code>πf⁺::Int</code> : FP format used for objective evaluation at <code>c</code></li><li><code>πg::Int</code> : FP format used for gradient evaluation at <code>c</code></li><li><code>πΔ::Int</code> : FP format used for model reduction computation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Solver" href="#MultiPrecisionR2.MPR2Solver"><code>MultiPrecisionR2.MPR2Solver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPR2Solver(MPnlp::FPMPNLPModel)</code></pre><p>Solver structure containing all the variables necessary to MRP2.</p><p><strong>Fields:</strong></p><ul><li><code>x::T</code>: incumbent</li><li>g::T : gradient</li><li>s::T : step </li><li>c::T : candidate</li><li>π::MPR2Precisions : FP format indices (precision) structure</li><li>p::MPR2Params : MPR2 parameters</li><li>x_norm::H : norm of <code>x</code></li><li>s_norm::H : norm of <code>s</code></li><li>g_norm::H : norm of <code>g</code></li><li>ΔT::H : model decrease</li><li>ρ::H : success ratio</li><li>ϕ::H : guaranteed upper bound on ||x||/||s||</li><li>ϕhat::H : computed value of ||x||/||s||</li><li>μ::H : error indicator</li><li>f::H : objective value at <code>x</code></li><li>f⁺::H : objective value at <code>c</code></li><li>ωf::H : objective evaluation error at <code>x</code>, |f(x) - fl(f(x))| &lt;= <code>ωf</code></li><li>ωf⁺::H : objective evaluation error at <code>c</code>, |f(c) - fl(f(c))| &lt;= <code>ωf⁺</code></li><li>ωg::H : gradient evaluation error at <code>c</code>, ||∇f(c) - fl(∇f(c))||₂ &lt;= <code>ωg</code>||fl(∇f(c))||₂</li><li>ωfBound::H : error tolerance on objective evaluation</li><li>σ::H : regularization parameter</li><li>πmax::Int : number of FP formats available for evaluations</li><li>init::Bool : initialized with <code>true</code>, set to <code>false</code> when entering main loop </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.CheckMPR2ParamConditions-Tuple{MPR2Params}" href="#MultiPrecisionR2.CheckMPR2ParamConditions-Tuple{MPR2Params}"><code>MultiPrecisionR2.CheckMPR2ParamConditions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CheckMPR2ParamConditions(p::MPR2Params{H})</code></pre><p>Check if the MPR2 parameters conditions are satified. See <a href="#MultiPrecisionR2.MPR2Params"><code>MPR2Params</code></a> for parameter conditions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradIntervalEval_test</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GradIntervalEval_test(nlp::AbstractNLPModel,FPList::AbstractArray)</code></pre><p>Test interval evaluation of gradient for all FP formats. Test fails and return an error if interval evaluation returns an error. See [<code>FPMPNLPModel</code>], [<code>AbstractNLPModel</code>]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradTypeStableTest</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GradTypeStableTest(nlp::AbstractNLPModel, FPList::AbstractArray)</code></pre><p>Tests if objective evaluation of <code>nlp</code> is type stable for FP format in FPList</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}" href="#MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}"><code>MultiPrecisionR2.MPR2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MPR2(MPnlp; kwargs...)</code></pre><p>An implementation of the quadratic regularization algorithm with dynamic selection of floating point format for objective and gradient evaluation, robust against finite precision rounding errors. Type parameters are: <code>S::AbstractVector</code>, <code>H::AbstractFloat</code>, <code>T::AbstractFloat</code>, <code>E::DataType</code> </p><p><strong>Arguments</strong></p><ul><li><code>MPnlp::FPMPNLPModel</code> : Multi precision model, see <code>FPMPNLPModel</code></li></ul><p>Keyword agruments:</p><ul><li><code>x₀::S = MPnlp.Model.meta.x0</code> : initial guess </li><li><code>par::MPR2Params = MPR2Params(MPnlp.FPList[1],H)</code> : MPR2 parameters, see <code>MPR2Params</code> for details</li><li><code>atol::H = H(sqrt(eps(T)))</code> : absolute tolerance on first order criterion </li><li><code>rtol::H = H(sqrt(eps(T)))</code> : relative tolerance on first order criterion</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function.</li><li><code>max_iter::Int = 1000</code> : maximum number of iteration allowed</li><li><code>σmin::T = sqrt(T(MPnlp.EpsList[end]))</code> : minimal value for regularization parameter. Value must be representable in any of the floating point formats of MPnlp. </li><li><code>verbose::Int=0</code> : display iteration information if &gt; 0</li><li><code>e::E</code> : user defined structure, used as argument for <code>compute_f_at_x!</code>, <code>compute_f_at_c!</code> <code>compute_g!</code> and <code>recompute_g!</code> callback functions.</li><li><code>compute_f_at_x!</code> : callback function to select precision and compute objective value and error bound at the current point. Allows to reevaluate the objective at x if more precision is needed.</li><li><code>compute_f_at_c!</code> : callback function to select precision and compute objective value and error bound at candidate.</li><li><code>compute_g!</code> : callback function to select precision and compute gradient value and error bound. Called at the end of main loop.</li><li><code>recompute_g!</code> : callback function to select precision and recompute gradient value if more precision is needed. Called after step, candidate and model decrease computation in main loop.</li><li><code>selectPic!</code> : callback function to select FP format of <code>c</code> at the next iteration</li></ul><p><strong>Outputs</strong></p><ol><li><code>GenericExecutionStats</code>: execution stats containing information about algorithm execution (nb. of iteration, termination status, ...). See <code>SolverCore.jl</code></li></ol><p><strong>Example</strong></p><pre><code class="language-julia hljs">T = [Float32, Float64]
f(x) = sum(x.^2)
x = ones(Float32,2)
mpnlp = FPMPNLPModel(f,x,T)
MPR2(mpnlp)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjIntervalEval_test</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ObjIntervalEval_test(nlp::AbstractNLPModel,FPList::AbstractArray)</code></pre><p>Test interval evaluation of objective for all formats in <code>FPList</code>. Test fails and return an error if interval evaluation returns an error. See [<code>FPMPNLPModel</code>], [<code>AbstractNLPModel</code>]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjTypeStableTest</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ObjTypeStableTest(nlp::AbstractNLPModel, FPList::AbstractArray)</code></pre><p>Tests if objective evaluation of <code>nlp</code> is type stable for FP format in FPList.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}" href="#MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}"><code>MultiPrecisionR2.check_overflow</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_overflow(f)</code></pre><ul><li><code>f::AbstractFloat</code>: Returns true if <code>f</code> is inf or nan, false otherwise.</li><li><code>f::Interval</code> : Returns true if <code>diam(f)</code> is inf or nan, false otherwise.</li><li><code>f::AbstractVector{AbstractFloat}</code> : Returns true if on element of <code>f</code> is inf or nan, false otherwise.</li><li><code>f::AbstractVector{Interval}</code>: Returns true if on element of <code>diam(f)</code> is inf, false otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple" href="#MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple"><code>MultiPrecisionR2.computeCandidate!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeCandidate!(c::T, x::T, s::T, FP::Vector{DataType}, π::MPR2Precisions) where {T &lt;: Tuple}</code></pre><p>Compute candidate with proper FP format to avoid underflow and overflow</p><p><strong>Arguments</strong></p><ul><li><code>x::T</code> : incumbent </li><li><code>s::T</code> : step</li><li><code>FP::Vector{Int}</code> : Available floating point formats</li><li><code>π::MPR2Precisions</code> : FP format index storage structure</li></ul><p><strong>Modified arguments:</strong></p><ul><li><code>c::T</code> : updated with candidate</li><li><code>π::MPR2Precisions</code> : <code>π.πc</code> updated with FP format index used for computation</li></ul><p><strong>Outputs:</strong></p><ul><li><code>::bool</code> : false if over/underflow occur with highest precision FP format, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}" href="#MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}"><code>MultiPrecisionR2.computeModelDecrease!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeModelDecrease!(g::T,s::T,solver::MPR2Solver,FP::Vector{DataType},π::MPR2Precisions) where {T &lt;: Tuple}</code></pre><p>Compute model decrease with FP format avoiding underflow and overflow</p><p><strong>Arguments</strong></p><ul><li><code>g::T</code> : gradient </li><li><code>s::T</code> : step</li><li><code>solver::MPR2Solver</code> : solver structure, stores intermediate variables</li><li><code>FP::Vector{Int}</code> : Available floating point formats</li><li><code>π::MPR2Precisions</code> : FP format index storage structure</li></ul><p><strong>Modified Arguments</strong></p><ul><li><code>solver::MPR2Solver</code> : <code>solver.ΔT</code> updated </li><li><code>π::MPR2Precisions</code> : <code>π.πΔ</code> updated </li></ul><p><strong>Outputs</strong></p><ul><li><code>::bool</code> : false if over/underflow occur with highest precision FP format, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}" href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>MultiPrecisionR2.computeMu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeMu(m::FPMPNLPModel, solver::MPR2Solver{T,H}; π::MPR2Precisions = solver.π)</code></pre><p>Compute μ value for gradient error ωg, ratio ϕ = ||x||/||s|| and rounding error models</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.computeStep!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeStep!(s::T, g::T, σ::H, FP::Vector{DataType}, π::MPR2Precisions) where {T &lt;: Tuple, H}</code></pre><p>Compute step with proper FP format to avoid underflow and overflow</p><p><strong>Arguments</strong></p><ul><li><code>s::T</code> : step </li><li><code>g::T</code> : gradient </li><li><code>πg::Int</code> : <code>g</code> FP index</li><li><code>σ::H</code> : regularization parameter</li><li><code>FP::Vector{Int}</code> : Available floating point formats</li><li><code>π::MPR2Precisions</code> : FP format index storage structure </li></ul><p><strong>Modified arguments :</strong></p><ul><li><code>s::T</code> : updated with computed step</li><li><code>π::MPR2Precisions</code> : <code>π.πs</code> updated with FP format used for step computation</li></ul><p><strong>Outputs</strong></p><ul><li><code>::bool</code> : false if over/underflow occurs, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_c_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_f_at_c_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute objective function at the candidate. Updates related fields of solver.</p><p><strong>Outputs:</strong></p><ul><li><code>::bool</code>: returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_x_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_f_at_x_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute objective function at the current incumbent. Updates related fields of solver.</p><p><strong>Outputs:</strong></p><ul><li><code>::bool</code> : returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_g_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_g_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute gradient at x if solver.init == true (first gradient eval outside of main loop), at c otherwise.</p><p><strong>Outputs:</strong></p><ul><li><code>::bool</code> : always true (needed to comply with callback template)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.get_id-Tuple{FPMPNLPModel, DataType}" href="#MultiPrecisionR2.get_id-Tuple{FPMPNLPModel, DataType}"><code>MultiPrecisionR2.get_id</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">get_id(m::FPMPNLPModel, FPFormat::DataType)</code></pre><p>Returns the index of <code>FPFormat</code> <code>in m.FPList</code>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gradReachPrec!(m::FPMPNLPModel{H}, x::T, g::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}
gradReachPrec(m::FPMPNLPModel{H}, x::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates gradient and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Arguments</strong></p><ul><li><code>m::FPMPNLPModel{H}</code>: multi precision model</li><li><code>x::T</code>: tuple containing value of x in the FP formats of <code>FPList</code></li><li><code>g::T</code>: gradient container</li><li><code>π</code>: Initial &#39;&#39;guess&#39;&#39; precision level that can provide evaluation error lower than <code>err_bound</code>, use 1 by default (lowest precision)</li></ul><p><strong>Outputs</strong></p><ol><li>(<code>g</code>): gradient, returned only with <code>gradReachPrec</code> call  </li><li><code>ωg</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ol><p><strong>Modified</strong></p><ul><li>(<code>g</code>): updated with the gradient value, only with <code>gradReachPrec!</code> call</li></ul><p>There is no guarantee that <code>ωg ≤ err_bound</code>. This case happens if the highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gradReachPrec!(m::FPMPNLPModel{H}, x::T, g::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}
gradReachPrec(m::FPMPNLPModel{H}, x::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates gradient and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Arguments</strong></p><ul><li><code>m::FPMPNLPModel{H}</code>: multi precision model</li><li><code>x::T</code>: tuple containing value of x in the FP formats of <code>FPList</code></li><li><code>g::T</code>: gradient container</li><li><code>π</code>: Initial &#39;&#39;guess&#39;&#39; precision level that can provide evaluation error lower than <code>err_bound</code>, use 1 by default (lowest precision)</li></ul><p><strong>Outputs</strong></p><ol><li>(<code>g</code>): gradient, returned only with <code>gradReachPrec</code> call  </li><li><code>ωg</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ol><p><strong>Modified</strong></p><ul><li>(<code>g</code>): updated with the gradient value, only with <code>gradReachPrec!</code> call</li></ul><p>There is no guarantee that <code>ωg ≤ err_bound</code>. This case happens if the highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}" href="#MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">graderrmp(m::FPMPNLPModel, x::V)
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{INT_ERR}) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{REL_ERR}) where {H, S, V&lt;:AbstractVector{S}}</code></pre><p>Evaluates the gradient g and the relative evaluation error ωg. The two functions with the extra argument <code>::Val{INT_ERR}</code> and <code>::Val{REL_ERR}</code> handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively.</p><p><strong>Arguments</strong></p><ul><li><code>m::FPMPNLPModel</code> : multi-precision model</li><li><code>x::V</code>: where the gradient is evaluated</li><li><code>g::V</code>: container for gradient</li></ul><p><strong>Outputs</strong></p><ol><li><code>g::Vector{S}</code>: gradient value, only returned with <code>graderrmp</code>.</li><li><code>ωg &lt;: AbstractFloat</code>: evaluation error satisfying: ||∇f(x) - fl(∇f(x))||₂ ≤ ωg||g||₂ with fl() the floating point evaluation.</li></ol><p>Note: ωg FP format may be different than <code>S</code></p><p><strong>Modified</strong></p><ul><li><code>g::V</code>: updated with gradient value</li></ul><p>Overflow cases:</p><ul><li>Interval evaluation: if at least one element of <code>g</code> has infinite diameter, returns [0]ⁿ, Inf</li><li>Classical evaluation: if at least one element of <code>g</code> overflows, returns <code>g, Inf</code> </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}" href="#MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">graderrmp(m::FPMPNLPModel, x::V)
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{INT_ERR}) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{REL_ERR}) where {H, S, V&lt;:AbstractVector{S}}</code></pre><p>Evaluates the gradient g and the relative evaluation error ωg. The two functions with the extra argument <code>::Val{INT_ERR}</code> and <code>::Val{REL_ERR}</code> handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively.</p><p><strong>Arguments</strong></p><ul><li><code>m::FPMPNLPModel</code> : multi-precision model</li><li><code>x::V</code>: where the gradient is evaluated</li><li><code>g::V</code>: container for gradient</li></ul><p><strong>Outputs</strong></p><ol><li><code>g::Vector{S}</code>: gradient value, only returned with <code>graderrmp</code>.</li><li><code>ωg &lt;: AbstractFloat</code>: evaluation error satisfying: ||∇f(x) - fl(∇f(x))||₂ ≤ ωg||g||₂ with fl() the floating point evaluation.</li></ol><p>Note: ωg FP format may be different than <code>S</code></p><p><strong>Modified</strong></p><ul><li><code>g::V</code>: updated with gradient value</li></ul><p>Overflow cases:</p><ul><li>Interval evaluation: if at least one element of <code>g</code> has infinite diameter, returns [0]ⁿ, Inf</li><li>Classical evaluation: if at least one element of <code>g</code> overflows, returns <code>g, Inf</code> </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}" href="#MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}"><code>MultiPrecisionR2.increment!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">increment!(nlp, s)</code></pre><p>Increment counter <code>s</code> of problem <code>nlp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.objReachPrec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">objReachPrec(m::FPMPNLPModel{H}, x::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates objective and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Arguments</strong></p><ul><li><code>m::FPMPNLPModel{H}</code>: multi precision model</li><li><code>x::T</code>: tuple containing value of x in the FP formats of <code>FPList</code></li><li><code>err_bound::H</code> : evaluation error tolerance</li><li><code>π::Int</code>: Initial &#39;&#39;guess&#39;&#39; for FP format that can provide evaluation error lower than <code>err_bound</code>, use 1 by default (lowest precision FP format)</li></ul><p><strong>Outputs</strong></p><ul><li><code>f</code>: objective value at <code>x</code></li><li><code>ωf</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ul><p>There is no guarantee that <code>ωf ≤ err_bound</code>, happens if highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S" href="#MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S"><code>MultiPrecisionR2.objerrmp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">objerrmp(m::FPMPNLPModel, x::AbstractVector{T})
objerrmp(m::FPMPNLPModel, x::AbstractVector{S}, ::Val{INT_ERR})
objerrmp(m::FPMPNLPModel, x::AbstractVector{S}, ::Val{REL_ERR})</code></pre><p>Evaluates the objective and the evaluation error. The two functions with the extra argument <code>::Val{INT_ERR}</code> and <code>::Val{REL_ERR}</code> handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively.</p><p><strong>Arguments</strong></p><ul><li><code>x::Vector{S}</code>: where to evaluate the objective, can be either a vector of <code>AbstractFloat</code> or a vector of <code>Intervals</code>.</li></ul><p><strong>Outputs</strong></p><ol><li>fl(f(x)): finite-precision evaluation of the objective at <code>x</code></li><li><code>ωf &lt;: AbstractFloat</code>: evaluation error, |f(x)-fl(f(x))| ≤ ωf with fl() the floating point evaluation.</li></ol><p>Overflow cases:</p><ul><li>Interval evaluation: overflow occurs if the diameter of the interval enclosing f(x) is Inf. Returns 0, Inf</li><li>Classical evaluation:<ul><li>If obj(x) = Inf: returns: Inf, Inf</li><li>If obj(x) != Inf and ωf = Inf, returns: obj(x), Inf  </li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.recomputeMu!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recomputeMu!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, πr::MPR2Precisions) where {T &lt;: Tuple, H}</code></pre><p>Recompute mu based on new precision levels.  Performs only necessary operations to recompute mu.  Possible operations are:</p><ul><li>recompute candidate with higher prec FP format to decrease u</li><li>recompute ϕhat and ϕ with higher FP format for norm computation of x and s</li><li>recompute step with greater precision: decrease μ denominator</li><li>recompute gradient with higher precision to decrease ωg</li><li>recompute model reduction with higher precision to decrease αfunc(n,U[π.πΔ])</li></ul><p>Does not make the over/underflow check as in main loop, since it is a repetition of the main loop with higher precisions and these issue shouldn&#39;t occur</p><p><strong>Outputs:</strong></p><ul><li><code>g_recompute::Bool</code> : true if gradient has been modified, false otherwise</li></ul><p>See <a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>recomputeMuPrecSelection!</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}" href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>MultiPrecisionR2.recomputeMuPrecSelection!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recomputeMuPrecSelection!(π::MPR2Precisions, πr::MPR2Precisions, πmax)</code></pre><p>Default strategy to select new precisions to recompute μ in the case where μ &gt; κₘ. Return false if no precision can be increased.</p><p><strong>Modified arguments:</strong></p><ul><li><code>πr</code>: contains new precision that will be used to recompute mu, see <a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>recomputeMu!</code></a></li></ul><p><strong>Ouptputs</strong></p><ul><li><code>max_prec::bool</code> : return true if maximum precision levels have been reached</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.recompute_g_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recompute_g_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Increase operation precision levels until sufficiently small μ indicator is achieved. See also <a href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>computeMu</code></a>, <a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>recomputeMuPrecSelection!</code></a>, <a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>recomputeMu!</code></a></p><p><strong>Outputs:</strong></p><ul><li><code>::bool</code> : returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}" href="#MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reset!(mpnlp::AbstractMPNLPModel)</code></pre><p>Reset evaluation count and model data (if appropriate) in <code>mpnlp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.reset!-Tuple{MPCounters}" href="#MultiPrecisionR2.reset!-Tuple{MPCounters}"><code>MultiPrecisionR2.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reset!(counters::MPCounters)</code></pre><p>Reset evaluation counters</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}" href="#MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}"><code>MultiPrecisionR2.selectPic_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">selectPic_default!(π::MPR2Precisions)</code></pre><p>Default strategy for selecting FP format of candidate for the next evaluation. Updates <code>solver.π.πf⁺</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}" href="#MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}"><code>MultiPrecisionR2.selectPif!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">selectPif!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, ωfBound::H)</code></pre><p>Select a precision for objective evaluation for candidate based on predicted evaluation error. Evaluation is predicted as:</p><ul><li>Relative error:<ul><li>Predicted value of objective at c: f(c) ≈ f(x) - ΔTk</li><li>Relative error model: ωf(c) = |f(c)| * RelErr</li></ul></li><li>Interval error:<ul><li>Predicted value of objective at c: f(c) ≈ f(x) - ΔTk</li><li>Interval evaluation error is proportional to f(x)</li><li>Interval evaluation error depends linearly with unit-roundoff </li></ul></li><li>Other: Lowest precision that does not cast candidate in a lower prec FP format and f(c) predicted does not overflow</li></ul><p><strong>Modified arguments:</strong></p><ul><li><code>solver.π.πf⁺</code>: updated with FP format index chosen for objective evaluation</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}" href="#MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.sum_counters</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">sum_counters(mpnlp)</code></pre><p>Sum all counters of problem <code>mpnlp</code> except <code>cons</code>, <code>jac</code>, <code>jprod</code> and <code>jtprod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.sum_counters-Tuple{MPCounters}" href="#MultiPrecisionR2.sum_counters-Tuple{MPCounters}"><code>MultiPrecisionR2.sum_counters</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">sum_counters(c::MPCounters)</code></pre><p>Sum all counters of <code>c</code> except <code>cons</code>, <code>jac</code>, <code>jprod</code> and <code>jtprod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S" href="#MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S"><code>MultiPrecisionR2.umpt!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">umpt!(x::Tuple, y::Vector{S})</code></pre><p>Update the elements of the multi precision containers <code>x</code> with the value <code>y</code>. Only the elements of <code>x</code> of FP formats with precision greater or equal than <code>y</code> are updated (avoid rounding error).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}" href="#MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}"><code>MultiPrecisionR2.update_struct!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update_struct!(str,other_str)</code></pre><p>Update the fields of <code>str</code> with the fields of <code>other_str</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}" href="#MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}"><code>MultiPrecisionR2.γfunc_test_error_bound</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">γfunc_test_error_bound(n::Int,eps::AbstractFloat,γfunc)</code></pre><p>Tests if γfunc callback provides strictly less than 100% error for dot product error of vector of size the dimension of the problem and the lowest machine epsilon.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.γfunc_test_template-Tuple{Any}" href="#MultiPrecisionR2.γfunc_test_template-Tuple{Any}"><code>MultiPrecisionR2.γfunc_test_template</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">γfunc_test_template(γfunc)</code></pre><p>Tests if γfunc callback function is properly implemented. Expected template: γfunc(n::Int,u::Float) -&gt; Float</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons(nlp)
neval_cons(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns the number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons_lin(nlp)
neval_cons_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns the number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons_nln(nlp)
neval_cons_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns the number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_grad-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_grad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_grad(nlp)
neval_grad(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>grad</code> evaluations. If extra argument T is provided, returns the number of <code>grad</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_hess-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_hess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_hess(nlp)
neval_hess(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>hess</code> evaluations. If extra argument T is provided, returns the number of <code>hess</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_hprod(nlp)
neval_hprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>hprod</code> evaluations. If extra argument T is provided, returns the number of <code>hprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac(nlp)
neval_jac(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns the number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac_lin(nlp)
neval_jac_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns the number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac_nln(nlp)
neval_jac_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns the number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jcon</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jcon(nlp)
neval_jcon(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jcon</code> evaluations. If extra argument T is provided, returns the number of <code>jcon</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jgrad(nlp)
neval_jgrad(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jgrad</code> evaluations. If extra argument T is provided, returns the number of <code>jgrad</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jhess(nlp)
neval_jhess(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jhess</code> evaluations. If extra argument T is provided, returns the number of <code>jhess</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jhprod(nlp)
neval_jhprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jhprod</code> evaluations. If extra argument T is provided, returns the number of <code>jhprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod(nlp)
neval_jprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns the number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod_lin(nlp)
neval_jprod_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns the number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod_nln(nlp)
neval_jprod_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns the number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod(nlp)
neval_jtprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns the number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod_lin(nlp)
neval_jtprod_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns the number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod_nln(nlp)
neval_jtprod_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns the number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_obj-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_obj-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_obj</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_obj(nlp)
neval_obj(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>obj</code> evaluations. If extra argument T is provided, returns the number of <code>obj</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../MPCounters/">MPCounters »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Tuesday 1 August 2023 18:45">Tuesday 1 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
