<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · MultiPrecisionR2.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="/reference/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="MultiPrecisionR2.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">MultiPrecisionR2.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/main/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><p>​</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><p>​</p><ul><li><a href="#Reference">Reference</a></li><li class="no-marker"><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></li></ul><p>​</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p>​</p><ul><li><a href="#MultiPrecisionR2.FPMPNLPModel"><code>MultiPrecisionR2.FPMPNLPModel</code></a></li><li><a href="#MultiPrecisionR2.MPCounters"><code>MultiPrecisionR2.MPCounters</code></a></li><li><a href="#MultiPrecisionR2.MPR2Params"><code>MultiPrecisionR2.MPR2Params</code></a></li><li><a href="#MultiPrecisionR2.MPR2Precisions"><code>MultiPrecisionR2.MPR2Precisions</code></a></li><li><a href="#MultiPrecisionR2.MPR2Precisions-Tuple{Int64}"><code>MultiPrecisionR2.MPR2Precisions</code></a></li><li><a href="#MultiPrecisionR2.MPR2Solver"><code>MultiPrecisionR2.MPR2Solver</code></a></li><li><a href="#MultiPrecisionR2.CheckMPR2ParamConditions-Union{Tuple{MPR2Params{H}}, Tuple{H}} where H"><code>MultiPrecisionR2.CheckMPR2ParamConditions</code></a></li><li><a href="#MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradIntervalEval_test</code></a></li><li><a href="#MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradTypeStableTest</code></a></li><li><a href="#MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}"><code>MultiPrecisionR2.MPR2</code></a></li><li><a href="#MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjIntervalEval_test</code></a></li><li><a href="#MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjTypeStableTest</code></a></li><li><a href="#MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}"><code>MultiPrecisionR2.check_overflow</code></a></li><li><a href="#MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple"><code>MultiPrecisionR2.computeCandidate!</code></a></li><li><a href="#MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}"><code>MultiPrecisionR2.computeModelDecrease!</code></a></li><li><a href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>MultiPrecisionR2.computeMu</code></a></li><li><a href="#MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.computeStep!</code></a></li><li><a href="#MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_c_default!</code></a></li><li><a href="#MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_x_default!</code></a></li><li><a href="#MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_g_default!</code></a></li><li><a href="#MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec</code></a></li><li><a href="#MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec!</code></a></li><li><a href="#MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp</code></a></li><li><a href="#MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp!</code></a></li><li><a href="#MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}"><code>MultiPrecisionR2.increment!</code></a></li><li><a href="#MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.objReachPrec</code></a></li><li><a href="#MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S"><code>MultiPrecisionR2.objerrmp</code></a></li><li><a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.recomputeMu!</code></a></li><li><a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>MultiPrecisionR2.recomputeMuPrecSelection!</code></a></li><li><a href="#MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.recompute_g_default!</code></a></li><li><a href="#MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.reset!</code></a></li><li><a href="#MultiPrecisionR2.reset!-Tuple{MPCounters}"><code>MultiPrecisionR2.reset!</code></a></li><li><a href="#MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}"><code>MultiPrecisionR2.selectPic_default!</code></a></li><li><a href="#MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}"><code>MultiPrecisionR2.selectPif!</code></a></li><li><a href="#MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.sum_counters</code></a></li><li><a href="#MultiPrecisionR2.sum_counters-Tuple{MPCounters}"><code>MultiPrecisionR2.sum_counters</code></a></li><li><a href="#MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S"><code>MultiPrecisionR2.umpt!</code></a></li><li><a href="#MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}"><code>MultiPrecisionR2.update_struct!</code></a></li><li><a href="#MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}"><code>MultiPrecisionR2.γfunc_test_error_bound</code></a></li><li><a href="#MultiPrecisionR2.γfunc_test_template-Tuple{Any}"><code>MultiPrecisionR2.γfunc_test_template</code></a></li><li><a href="#NLPModels.neval_cons-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons</code></a></li><li><a href="#NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_lin</code></a></li><li><a href="#NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_nln</code></a></li><li><a href="#NLPModels.neval_grad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_grad</code></a></li><li><a href="#NLPModels.neval_hess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hess</code></a></li><li><a href="#NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hprod</code></a></li><li><a href="#NLPModels.neval_jac-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac</code></a></li><li><a href="#NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_lin</code></a></li><li><a href="#NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_nln</code></a></li><li><a href="#NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jcon</code></a></li><li><a href="#NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jgrad</code></a></li><li><a href="#NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhess</code></a></li><li><a href="#NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhprod</code></a></li><li><a href="#NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod</code></a></li><li><a href="#NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_lin</code></a></li><li><a href="#NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_nln</code></a></li><li><a href="#NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod</code></a></li><li><a href="#NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_lin</code></a></li><li><a href="#NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_nln</code></a></li><li><a href="#NLPModels.neval_obj-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_obj</code></a></li></ul><p>​</p><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.FPMPNLPModel" href="#MultiPrecisionR2.FPMPNLPModel"><code>MultiPrecisionR2.FPMPNLPModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FPMPNLPModel(Model::AbstractNLPModel{D,S},FPList::Vector{K}; kwargs...) where {D,S,K&lt;:DataType}
FPMPNLPModel(f,x0, FPList::Vector{DataType})</code></pre><p>Floating-Point Multi-Precision Non Linear Model structure. This structure is intended to be used as MPR2Solver input.</p><p>Primairly stores NLPmodels instanciated with different Floating Point formats and provide errors on objective function and grandient evaluation (see <code>objerrmp</code> and <code>graderrmp</code>). The error models are :</p><ul><li>ojective: |fl(f(x)) - f(x)| ≤ ωf</li><li>gradient: |fl(∇f(x)) - ∇f(x)| ≤ ||fl(∇f(x))||₂ ωg.</li></ul><p>ωf and ωg are needed for MPR2Solver. They are evaluated either using:</p><ul><li>interval analysis (can be very slow)</li><li>based on relative error assumption (see <code>ωfRelErr</code> and <code>ωgRelErr</code> field description below)   </li></ul><p><strong>Fields</strong></p><ul><li><code>Model::AbstractNLPModel</code> : NLPModel</li><li><code>FPList::Vector{DataType}</code> : List of floating point formats</li><li><code>EpsList::Vector{H}</code> : List of machine epsilons of the floating point formats</li><li><code>HPFormat::DataType</code> : High precision floating point format, used for intermediate value computation in MPR2Solver. Is H parameter.</li><li><code>γfunc</code> : callback function for dot product rounding error parameter |γ|, |fl(x.y) - x.y| ≤ |x|.|y| γ. Expected signature is <code>γfunc(n::Int,u::H)</code> and output is <code>H</code>. Default callback <code>γfunc(n::Int,u::H) = n*u</code> is implemented upon instanciation. </li><li><code>ωfRelErr::Vector{H}</code> : List of relative error factor for objective function evaluation for formats in <code>FPList</code>. Error model is |f(x)-fl(f(x))| ≤ ωfRelErr * |fl(f(x))| </li><li><code>ωgRelErr::Vector{H}</code> : List of relative error factor for gradient evaluation for formats in <code>FPList</code>. Error model is |∇f(x)-fl(∇f(x))| ≤ ωgRelErr * ||fl(∇f(x))||₂ </li><li><code>ObjEvalMode::Int</code> : Evalutation mode for objective and error. Set automatically upon instanciation. Possible values:<ul><li><code>INT_ERR</code> : interval evaluation of objective (chosen as middle of the interval) and error</li><li><code>REL_ERR</code> : classical evaluation and use relative error model (with ωfRelErr value)</li></ul></li><li><code>GradEvalMode::Int</code> : Evalutation mode for gradient and error. Set automatically upon instanciation. Possible values:<ul><li><code>INT_ERR</code> : interval evaluation of gradient (chosen as middle of interval vector) and error</li><li><code>REL_ERR</code> : classical evaluation and use relative error model (with ωgRelErr value)</li></ul></li></ul><p><strong>Constructors:</strong></p><ul><li><code>FPMPModel(Model::AbstractNLPModel, FPList::Vector{DataType}; nvar=100, kwargs...)</code> : create a FPMPModel from Model with FPList precisions</li><li><code>FPMPModel(s::symbol,FPList::Vector{DataType}; nvar=100, kwargs...)</code> : create a FPMPModel from a symbol linked to an AbstractNLPModel.</li><li><code>FPModels</code>(f,x0::Vector,FPList::Vector{DataType}; nvar=100, kwargs...)</li></ul><p>Keyword arguments: </p><ul><li>nvar: dimension of the problem (if scalable)</li><li>kwargs: <ul><li><code>HPFormat=Float64</code> : high precision format (must be at least as accurate as FPList[end])</li><li><code>γfunc=nothing</code> : use default if not provided (see Fields section above)</li><li><code>ωfRelErr=nothing</code> : use interval evaluation if not provided</li><li><code>ωgRelErr=nothing</code> : use interval evaluation if not provided</li></ul></li></ul><p><strong>Checks upon instanciation</strong></p><p>Some checks are performed upon instanciation. These checks include:</p><ul><li>Length consistency of vector fields:  FPList, EpsList</li><li>HPFormat is at least as accurate as the highest precision floating point format in <code>FPList</code>`. Ideally HPFormat is more accurate to ensure the numerical stability of MPR2 algorithm.</li><li>Interval evaluations: it might happen that interval evaluation of objective function and/or gradient is type-unstable or returns an error. The constructor returns an error in this case. This type of error is most likely due to <code>IntervalArithmetic.jl</code>.</li><li>FPList is ordered by increasing floating point format accuracy</li></ul><p>This checks can return <code>@warn</code> or <code>error</code>. </p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">T = [Float16, Float32]
f(x) = x[1]^2 + x[2]^2
x = zeros(2)
MPmodel = FPMPNLPModel(f,x0,T)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L20-L79">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPCounters" href="#MultiPrecisionR2.MPCounters"><code>MultiPrecisionR2.MPCounters</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPCounters</code></pre><p>Struct for storing the number of function evaluations with each floating point format. The fields are the same as <a href="https://jso.dev/NLPModels.jl/stable/reference/#NLPModels.Counters">NLPModels.Counters</a>, but contains a <code>Dict{DataType,Int}</code>.</p><hr/><pre><code class="nohighlight hljs">MPCounters(FPformats::Vector{DataType})</code></pre><p>Creates an empty MPCounters struct for types in the vector <code>FPformats</code>.</p><pre><code class="language-julia hljs">using MultiPrecisionR2.jl
FPformats = [Float16, Float32]
cntrs = MPCounters(FPformats)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L3-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Params" href="#MultiPrecisionR2.MPR2Params"><code>MultiPrecisionR2.MPR2Params</code></a> — <span class="docstring-category">Type</span></header><section><div><p>MPR2Params(LPFormat::DataType, HPFormat::DataType) MPR2 parameters.</p><p><strong>Fields</strong></p><ul><li><code>η₀::H</code> : controls objective function error tolerance, convergence condition is ωf ≤ η₀ ΔT (see <code>FPMPNLPModel</code> for details on ωf)</li><li><code>η₁::H</code> : step successful if ρ ≥ η₁ (update incumbent)</li><li><code>η₂::H</code> : step very successful if ρ ≥ η₂ (decrease σ ⟹ increase step length)</li><li><code>κₘ::H</code> : tolerance on gradient evaluation error, μ ≤ κₘ (see <code>computeMu</code>) </li><li><code>γ₁::L</code> : σk+1 = σk * γ₁ if ρ ≥ η₂</li><li><code>γ₂::L</code> : σk+1 = σk * γ₂ if ρ &lt; η₁</li></ul><p><strong>Parameters</strong></p><ul><li><code>H</code> must correspond to <code>MPnlp.HPFormat</code> with <code>MPnlp</code> given as input of <code>MPR2</code></li><li><code>L</code> must correspond to <code>MPnlp.FPList[1]</code>, i.e the lowest precision floating point format used by <code>MPnlp</code> given as input of <code>MPR2</code></li></ul><p><strong>Conditions</strong></p><p>Parameters must statisfy the following conditions:</p><ul><li>0 ≤ η₀ ≤ 1/2*η₁</li><li>0 ≤ η₁ ≤ η₂ &lt; 1</li><li>η₀+κₘ/2 ≤0.5*(1-η₂)</li><li>η₂&lt;1 </li><li>0&lt;γ₁&lt;1&lt;γ₂</li></ul><p>Instiates default values:</p><ul><li><code>η₀::H = 0.01</code></li><li><code>η₁::H = 0.02</code></li><li><code>η₂::H = 0.95</code></li><li><code>κₘ::H = 0.02</code> </li><li><code>γ₁::L = 2^(-2)</code></li><li><code>γ₂::L = 2</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L45-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Precisions" href="#MultiPrecisionR2.MPR2Precisions"><code>MultiPrecisionR2.MPR2Precisions</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">function MPR2Precisions(π::Int)</code></pre><p>Precision  of variables and precision evaluation of obj, grad, model reduction and norms. Precisions are represented by integers, and correspond to FP format of corresponding index in <code>FPMPNLPModel.FPList</code>. i.e., precision <code>i</code> correpsonds to FP format <code>FPMPNLPModel.FPList[i]</code> See <code>FPMPNLPModel</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L19-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Precisions-Tuple{Int64}" href="#MultiPrecisionR2.MPR2Precisions-Tuple{Int64}"><code>MultiPrecisionR2.MPR2Precisions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">function MPR2Precisions(π::Int)</code></pre><p>Precision  of variables and precision evaluation of obj, grad, model reduction and norms. Precisions are represented by integers, and correspond to FP format of corresponding index in <code>FPMPNLPModel.FPList</code>. i.e., precision <code>i</code> correpsonds to FP format <code>FPMPNLPModel.FPList[i]</code> See <code>FPMPNLPModel</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2Solver" href="#MultiPrecisionR2.MPR2Solver"><code>MultiPrecisionR2.MPR2Solver</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MPR2(MPnlp; kwargs...)</code></pre><p>An implementation of the quadratic regularization algorithm with dynamic selection of floating point format for objective and gradient evaluation, robust against finite precision rounding errors.</p><p><strong>Arguments</strong></p><ul><li><code>MPnlp::FPMPNLPModel</code> : Multi precision model, see <code>FPMPNLPModel</code></li></ul><p>Keyword agruments:</p><ul><li><code>x₀::S = MPnlp.Model.meta.x0</code> : initial guess </li><li><code>par::MPR2Params = MPR2Params(MPnlp.FPList[1],H)</code> : MPR2 parameters, see <code>MPR2Params</code> for details</li><li><code>atol::H = H(sqrt(eps(T)))</code> : absolute tolerance on first order criterion </li><li><code>rtol::H = H(sqrt(eps(T)))</code> : relative tolerance on first order criterion</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function.</li><li><code>max_iter::Int = 1000</code> : maximum number of iteration allowed</li><li><code>σmin::T = sqrt(T(MPnlp.EpsList[end]))</code> : minimal value for regularization parameter. Value must be representable in any of the floating point formats of MPnlp. </li><li><code>verbose::Int=0</code> : display iteration information if &gt; 0</li><li><code>e::E</code> : user defined structure, used as argument for <code>compute_f_at_x!</code>, <code>compute_f_at_c!</code> <code>compute_g!</code> and <code>recompute_g!</code> callback functions.</li><li><code>compute_f_at_x!</code> : callback function to select precision and compute objective value and error bound at the current point. Allows to reevaluate the objective at x if more precision is needed.</li><li><code>compute_f_at_c!</code> : callback function to select precision and compute objective value and error bound at candidate.</li><li><code>compute_g!</code> : callback function to select precision and compute gradient value and error bound. Called at the end of main loop.</li><li><code>recompute_g!</code> : callback function to select precision and recompute gradient value if more precision is needed. Called after step, candidate and model decrease computation in main loop.</li><li><code>selectPic!</code> : callback function to select FP format of <code>c</code> at the next iteration</li></ul><p><strong>Outputs</strong></p><p>Returns a <code>GenericExecutionStats</code>, see <code>SolverCore.jl</code> <code>GenericExecutionStats.status</code> is set to <code>:exception</code> </p><p><strong>Example</strong></p><pre><code class="language-julia hljs">T = [Float16, Float32]
f(x) = x[1]^2+x[2]^2
x = ones(2)
nlp_list = [ADNLPModel(f,t.(x)) for t in T ]
MPnlp = FPMPNLPModel(nlp_list)
mpr2s(MPnlp) </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L109-L142">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.CheckMPR2ParamConditions-Union{Tuple{MPR2Params{H}}, Tuple{H}} where H" href="#MultiPrecisionR2.CheckMPR2ParamConditions-Union{Tuple{MPR2Params{H}}, Tuple{H}} where H"><code>MultiPrecisionR2.CheckMPR2ParamConditions</code></a> — <span class="docstring-category">Method</span></header><section><div><p>CheckMPR2ParamConditions(p::MPR2Params{H})</p><p>Check if the MPR2 parameters conditions are satified. See <a href="#MultiPrecisionR2.MPR2Params"><code>MPR2Params</code></a> for parameter conditions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L96-L101">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.GradIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradIntervalEval_test</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GradIntervalEval_test(nlp::AbstractNLPModel,FPList::AbstractArray)</code></pre><p>Test interval evaluation of gradient for all FP formats. Test fails and return an error if interval evaluation returns an error. See [<code>FPMPNLPModel</code>], [<code>AbstractNLPModel</code>]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L29-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.GradTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.GradTypeStableTest</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">GradTypeStableTest(nlp::AbstractNLPModel, FPList::AbstractArray)</code></pre><p>Tests if objective evaluation of <code>nlp</code> is type stable for FP format in FPList</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L72-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}" href="#MultiPrecisionR2.MPR2-Tuple{FPMPNLPModel}"><code>MultiPrecisionR2.MPR2</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MPR2(MPnlp; kwargs...)</code></pre><p>An implementation of the quadratic regularization algorithm with dynamic selection of floating point format for objective and gradient evaluation, robust against finite precision rounding errors.</p><p><strong>Arguments</strong></p><ul><li><code>MPnlp::FPMPNLPModel</code> : Multi precision model, see <code>FPMPNLPModel</code></li></ul><p>Keyword agruments:</p><ul><li><code>x₀::S = MPnlp.Model.meta.x0</code> : initial guess </li><li><code>par::MPR2Params = MPR2Params(MPnlp.FPList[1],H)</code> : MPR2 parameters, see <code>MPR2Params</code> for details</li><li><code>atol::H = H(sqrt(eps(T)))</code> : absolute tolerance on first order criterion </li><li><code>rtol::H = H(sqrt(eps(T)))</code> : relative tolerance on first order criterion</li><li><code>max_eval::Int = -1</code>: maximum number of evaluation of the objective function.</li><li><code>max_iter::Int = 1000</code> : maximum number of iteration allowed</li><li><code>σmin::T = sqrt(T(MPnlp.EpsList[end]))</code> : minimal value for regularization parameter. Value must be representable in any of the floating point formats of MPnlp. </li><li><code>verbose::Int=0</code> : display iteration information if &gt; 0</li><li><code>e::E</code> : user defined structure, used as argument for <code>compute_f_at_x!</code>, <code>compute_f_at_c!</code> <code>compute_g!</code> and <code>recompute_g!</code> callback functions.</li><li><code>compute_f_at_x!</code> : callback function to select precision and compute objective value and error bound at the current point. Allows to reevaluate the objective at x if more precision is needed.</li><li><code>compute_f_at_c!</code> : callback function to select precision and compute objective value and error bound at candidate.</li><li><code>compute_g!</code> : callback function to select precision and compute gradient value and error bound. Called at the end of main loop.</li><li><code>recompute_g!</code> : callback function to select precision and recompute gradient value if more precision is needed. Called after step, candidate and model decrease computation in main loop.</li><li><code>selectPic!</code> : callback function to select FP format of <code>c</code> at the next iteration</li></ul><p><strong>Outputs</strong></p><p>Returns a <code>GenericExecutionStats</code>, see <code>SolverCore.jl</code> <code>GenericExecutionStats.status</code> is set to <code>:exception</code> </p><p><strong>Example</strong></p><pre><code class="language-julia hljs">T = [Float16, Float32]
f(x) = x[1]^2+x[2]^2
x = ones(2)
nlp_list = [ADNLPModel(f,t.(x)) for t in T ]
MPnlp = FPMPNLPModel(nlp_list)
mpr2s(MPnlp) </code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L191">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.ObjIntervalEval_test-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjIntervalEval_test</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ObjIntervalEval_test(nlp::AbstractNLPModel,FPList::AbstractArray)</code></pre><p>Test interval evaluation of objective for all formats in <code>FPList</code>. Test fails and return an error if interval evaluation returns an error. See [<code>FPMPNLPModel</code>], [<code>AbstractNLPModel</code>]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}" href="#MultiPrecisionR2.ObjTypeStableTest-Tuple{NLPModels.AbstractNLPModel, AbstractArray}"><code>MultiPrecisionR2.ObjTypeStableTest</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ObjTypeStableTest(nlp::AbstractNLPModel, FPList::AbstractArray)</code></pre><p>Tests if objective evaluation of <code>nlp</code> is type stable for FP format in FPList.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L55-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}" href="#MultiPrecisionR2.check_overflow-Tuple{AbstractFloat}"><code>MultiPrecisionR2.check_overflow</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_overflow(f)</code></pre><ul><li>f::AbstractFloat: Returns true if <code>f</code> is inf or nan, false otherwise.</li><li>f::Interval : Returns true if <code>diam(f)</code> is inf or nan, false otherwise.</li><li>f::AbstractVector{AbstractFloat} : Returns true if on element of <code>f</code> is inf or nan, false otherwise.</li><li>f::AbstractVector{Interval} : Returns true if on element of <code>diam(f)</code> is inf, false otherwise.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L117-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple" href="#MultiPrecisionR2.computeCandidate!-Union{Tuple{T}, Tuple{T, T, T, Vector{DataType}, MPR2Precisions}} where T&lt;:Tuple"><code>MultiPrecisionR2.computeCandidate!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeCandidate!(c::T, x::T, s::T, FP::Vector{DataType}, π::MPR2Precisions) where {T &lt;: Tuple}</code></pre><p>Compute candidate with FP format avoiding underflow and overflow</p><p><strong>Arguments</strong></p><ul><li>x::Vector{T} : incumbent </li><li>s::Vector{T} : step</li><li>FP::Vector{Int} : Available floating point formats</li><li>π::MPR2Precisions</li></ul><p><strong>Modified arguments:</strong></p><ul><li>c::Vector{T} : candidate</li><li>π::MPR2Precisions : π.πc updated</li></ul><p><strong>Outputs</strong></p><ul><li>::bool : false if over/underflow occur with highest precision FP format, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L497-L513">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}" href="#MultiPrecisionR2.computeModelDecrease!-Union{Tuple{T}, Tuple{H}, Tuple{T, T, MPR2Solver{T, H}, Vector{DataType}, MPR2Precisions}} where {H, T&lt;:Tuple}"><code>MultiPrecisionR2.computeModelDecrease!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeModelDecrease!(g::T,s::T,solver::MPR2Solver,FP::Vector{DataType},π::MPR2Precisions) where {T &lt;: Tuple}</code></pre><p>Compute model decrease with FP format avoiding underflow and overflow</p><p><strong>Arguments</strong></p><ul><li>g::Vector{T} : gradient </li><li>s::Vector{T} : step</li><li>solver::MPR2Solver: algo status</li><li>FP::Vector{Int} : Available floating point formats</li><li>π::MPR2Precisions : hold the FP format indices</li></ul><p><strong>Modified Arguments</strong></p><ul><li>solver::MPR2Solver : solver.ΔT updated </li><li>π::MPR2Precisions : π.πΔ updated </li></ul><p><strong>Outputs</strong></p><ul><li>::bool : false if over/underflow occur with highest precision FP format, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L540-L559">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}" href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>MultiPrecisionR2.computeMu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeMu(m::FPMPNLPModel, solver::MPR2Solver{T,H}; π::MPR2Precisions = solver.π)</code></pre><p>Compute μ value for gradient error ωg, ratio ϕ = ||x||/||s|| and rounding error models</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L587-L591">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.computeStep!-Union{Tuple{H}, Tuple{T}, Tuple{T, T, H, Vector{DataType}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.computeStep!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">computeStep!(s::T, g::T, σ::H, FP::Vector{DataType}, π::MPR2Precisions) where {T &lt;: Tuple, H}</code></pre><p>Compute step with FP format avoiding underflow and overflow</p><p><strong>Arguments</strong></p><ul><li><code>s::Vector{T}</code> : step </li><li><code>g::Vector{T}</code> : gradient </li><li><code>πg::Int</code> : <code>g</code> FP index</li><li><code>σ::H</code> : regularization parameter</li><li><code>FP::Vector{Int}</code> : Available floating point formats</li></ul><p><strong>Modified arguments :</strong></p><ul><li><code>s::Vector</code> : step vector container</li><li><code>π::MPR2Precisions</code> : hold the FP format indices</li></ul><p><strong>Output</strong></p><ul><li>::bool : false if over/underflow occur, true otherwise</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L451-L467">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_f_at_c_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_c_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_f_at_c_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute objective function at the candidate. Updates related fields of solver.</p><p><strong>Outputs:</strong></p><p>*bool : returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L731-L739">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_f_at_x_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_f_at_x_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_f_at_x_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute objective function at the current incumbent. Updates related fields of solver.</p><p><strong>Outputs:</strong></p><p>*bool : returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L760-L768">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.compute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.compute_g_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">compute_g_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Compute gradient at x if solver.init == true (first gradient eval outside of main loop), at c otherwise.</p><p><strong>Outputs:</strong></p><p>*bool : always returns true (comply with callback template)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L799-L806">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.gradReachPrec!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gradReachPrec!(m::FPMPNLPModel{H}, x::T, g::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates gradient and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Inputs</strong></p><ul><li><code>π</code>: Initial &#39;&#39;gess&#39;&#39; for precision level that can provide evaluation error lower than <code>err_bound</code>, uses 1 by default (lowest precision)</li></ul><p><strong>Outputs</strong></p><ul><li><code>ωg</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ul><p>There is no guarantee that <code>ωg ≤ err_bound</code>. This case happens if the highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L368-L378">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.gradReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.gradReachPrec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gradReachPrec!(m::FPMPNLPModel{H}, x::T, g::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates gradient and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Inputs</strong></p><ul><li><code>π</code>: Initial &#39;&#39;gess&#39;&#39; for precision level that can provide evaluation error lower than <code>err_bound</code>, uses 1 by default (lowest precision)</li></ul><p><strong>Outputs</strong></p><ul><li><code>ωg</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ul><p>There is no guarantee that <code>ωg ≤ err_bound</code>. This case happens if the highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L404">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}" href="#MultiPrecisionR2.graderrmp!-Union{Tuple{V}, Tuple{S}, Tuple{H}, Tuple{FPMPNLPModel{H}, V, V}} where {H, S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">graderrmp!(m::FPMPNLPModel{H}, x::V, g::V) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{INT_ERR}) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{REL_ERR}) where {H, S, V&lt;:AbstractVector{S}}</code></pre><p>Evaluates the gradient g and the relative evaluation error ωg. The two functions with the extra argument ::Val{INT<em>ERR} and ::Val{REL</em>ERR} handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively. Inputs: x::Vector{S} with S in m.FPList Outputs: g::Vector{S}, ωg &lt;: AbstractFloat satisfying: ||∇f(x) - fl(∇f(x))||₂ ≤ ωg||g||₂ with fl() the floating point evaluation. Note: ωg FP format may be different than S Overflow cases:</p><ul><li>Interval evaluation: if at least one element of g has infinite diameter, returns [0]ⁿ, Inf</li><li>Classical evaluation: if one element of g overflow, returns g, Inf </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L260-L272">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}" href="#MultiPrecisionR2.graderrmp-Union{Tuple{V}, Tuple{S}, Tuple{FPMPNLPModel, V}} where {S, V&lt;:AbstractVector{S}}"><code>MultiPrecisionR2.graderrmp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">graderrmp!(m::FPMPNLPModel{H}, x::V, g::V) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{INT_ERR}) where {H, S, V&lt;:AbstractVector{S}}
graderrmp!(m::FPMPNLPModel{H}, x::V, g::V, ::Val{REL_ERR}) where {H, S, V&lt;:AbstractVector{S}}</code></pre><p>Evaluates the gradient g and the relative evaluation error ωg. The two functions with the extra argument ::Val{INT<em>ERR} and ::Val{REL</em>ERR} handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively. Inputs: x::Vector{S} with S in m.FPList Outputs: g::Vector{S}, ωg &lt;: AbstractFloat satisfying: ||∇f(x) - fl(∇f(x))||₂ ≤ ωg||g||₂ with fl() the floating point evaluation. Note: ωg FP format may be different than S Overflow cases:</p><ul><li>Interval evaluation: if at least one element of g has infinite diameter, returns [0]ⁿ, Inf</li><li>Classical evaluation: if one element of g overflow, returns g, Inf </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L330">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}" href="#MultiPrecisionR2.increment!-Tuple{AbstractMPNLPModel, Symbol, DataType}"><code>MultiPrecisionR2.increment!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">increment!(nlp, s)</code></pre><p>Increment counter <code>s</code> of problem <code>nlp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L65-L69">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.objReachPrec-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel{H}, T, H}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.objReachPrec</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">objReachPrec(m::FPMPNLPModel{H}, x::T, err_bound::H; π::Int = 1) where {T &lt;: Tuple, H}</code></pre><p>Evaluates objective and increase model precision to reach necessary error bound or to avoid overflow.</p><p><strong>Inputs</strong></p><ul><li><code>π</code>: Initial &#39;&#39;guess&#39;&#39; precision level that can provide evaluation error lower than <code>err_bound</code>, use 1 by default (lowest precision)</li></ul><p><strong>Outputs</strong></p><ul><li><code>f</code>: objective value at <code>x</code></li><li><code>ωf</code>: objective evaluation error</li><li><code>id</code>: precision level used for evaluation</li></ul><p>There is no guarantee that <code>ωf ≤ err_bound</code>, happens if highest precision FP format is not accurate enough.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L338-L350">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S" href="#MultiPrecisionR2.objerrmp-Union{Tuple{S}, Tuple{FPMPNLPModel, AbstractVector{S}}} where S"><code>MultiPrecisionR2.objerrmp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">objerrmp(m::FPMPNLPModel, x::AbstractVector{T})
objerrmp(m::FPMPNLPModel, x::AbstractVector{S}, ::Val{INT_ERR})
objerrmp(m::FPMPNLPModel, x::AbstractVector{S}, ::Val{REL_ERR})</code></pre><p>Evaluates the objective and the evaluation error. The two functions with the extra argument ::Val{INT<em>ERR} and ::Val{REL</em>ERR} handles the interval and &quot;classic&quot; evaluation of the objective and the error, respectively. Inputs: x::Vector{S}, can be either a vector of AbstractFloat or a vector of Intervals. Outputs: fl(f(x)), ωf &lt;: AbstractFloat, where |f(x)-fl(f(x))| ≤ ωf with fl() the floating point evaluation. Overflow cases:</p><ul><li>Interval evaluation: overflow occurs if the diameter of the interval enclosing f(x) is Inf. Returns 0, Inf</li><li>Classical evaluation:<ul><li>If obj(x) = Inf: returns: Inf, Inf</li><li>If obj(x) != Inf and ωf = Inf, returns: obj(x), Inf  </li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPNLPModels.jl#L215-L228">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}" href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>MultiPrecisionR2.recomputeMu!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recomputeMu!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, πr::MPR2Precisions) where {T &lt;: Tuple, H}</code></pre><p>Recompute mu based on new precision levels.  Performs only necessary operations to recompute mu.  Possible operations are:</p><ul><li>recompute candidate with higher prec FP format to decrease u</li><li>recompute ϕhat and ϕ with higher FP format for norm computation of x and s</li><li>recompute step with greater precision: decrease μ denominator</li><li>recompute gradient with higher precision to decrease ωg</li><li>recompute model reduction with higher precision to decrease αfunc(n,U[π.πΔ])</li></ul><p>Does not make the over/underflow check as in main loop, since it is a repetition of the main loop with higher precisions and these issue shouldn&#39;t occur</p><p><strong>Outputs:</strong></p><ul><li>g_recompute::Bool : true if gradient has been modified, false otherwise</li></ul><p>See <a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>recomputeMuPrecSelection!</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L636-L652">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}" href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>MultiPrecisionR2.recomputeMuPrecSelection!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recomputeMuPrecSelection!(π::MPR2Precisions, πr::MPR2Precisions, πmax)</code></pre><p>Default strategy to select new precisions to recompute μ in the case where μ &gt; κₘ. Return false if no precision can be increased.</p><p><strong>Modified arguments:</strong></p><ul><li>πr: contains new precision that will be used to recompute mu, see <a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>recomputeMu!</code></a></li></ul><p><strong>Ouptputs</strong></p><ul><li>max_prec::bool : return true if maximum precision levels have been reached</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L604-L612">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}" href="#MultiPrecisionR2.recompute_g_default!-Union{Tuple{T}, Tuple{E}, Tuple{H}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, SolverCore.GenericExecutionStats, E}} where {H, E, T&lt;:Tuple}"><code>MultiPrecisionR2.recompute_g_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">recompute_g_default!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, stats::GenericExecutionStats, e::E)</code></pre><p>Increase operation precision levels until sufficiently small μ indicator is achieved. See also <a href="#MultiPrecisionR2.computeMu-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}}} where {T, H}"><code>computeMu</code></a>, <a href="#MultiPrecisionR2.recomputeMuPrecSelection!-Tuple{MPR2Precisions, MPR2Precisions, Any}"><code>recomputeMuPrecSelection!</code></a>, <a href="#MultiPrecisionR2.recomputeMu!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, MPR2Precisions}} where {T&lt;:Tuple, H}"><code>recomputeMu!</code></a></p><p><strong>Outputs:</strong></p><p>*bool : returns false if couldn&#39;t reach sufficiently small evaluation error or overflow occured. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L823-L831">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}" href="#MultiPrecisionR2.reset!-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reset!(mpnlp::AbstractMPNLPModel)</code></pre><p>Reset evaluation count and model data (if appropriate) in <code>mpnlp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L131-L135">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.reset!-Tuple{MPCounters}" href="#MultiPrecisionR2.reset!-Tuple{MPCounters}"><code>MultiPrecisionR2.reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">reset!(counters::MPCounters)</code></pre><p>Reset evaluation counters</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L115-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}" href="#MultiPrecisionR2.selectPic_default!-Tuple{MPR2Solver}"><code>MultiPrecisionR2.selectPic_default!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">selectPic_default!(π::MPR2Precisions)</code></pre><p>Default strategy for selecting FP format of candidate for the next evaluation. Updates <code>solver.π.πf⁺</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L721-L725">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}" href="#MultiPrecisionR2.selectPif!-Union{Tuple{H}, Tuple{T}, Tuple{FPMPNLPModel, MPR2Solver{T, H}, H}} where {T, H}"><code>MultiPrecisionR2.selectPif!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">selectPif!(m::FPMPNLPModel, solver::MPR2Solver{T,H}, ωfBound::H)</code></pre><p>Select a precision for objective evaluation for candidate based on predicted evaluation error. Evaluation is predicted as:</p><ul><li>Relative error:<ul><li>Predicted value of objective at c: f(c) ≈ f(x) - ΔTk</li><li>Relative error model: ωf(c) = |f(c)| * RelErr</li></ul></li><li>Interval error:<ul><li>Predicted value of objective at c: f(c) ≈ f(x) - ΔTk</li><li>Interval evaluation error is proportional to f(x)</li><li>Interval evaluation error depends linearly with unit-roundoff </li></ul></li><li>Other: Lowest precision that does not cast candidate in a lower prec FP format and f(c) predicted does not overflow</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L685-L699">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}" href="#MultiPrecisionR2.sum_counters-Tuple{AbstractMPNLPModel}"><code>MultiPrecisionR2.sum_counters</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">sum_counters(mpnlp)</code></pre><p>Sum all counters of problem <code>nlp</code> except <code>cons</code>, <code>jac</code>, <code>jprod</code> and <code>jtprod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L108-L112">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.sum_counters-Tuple{MPCounters}" href="#MultiPrecisionR2.sum_counters-Tuple{MPCounters}"><code>MultiPrecisionR2.sum_counters</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">sum_counters(c::MPCounters)</code></pre><p>Sum all counters of <code>counters</code> except <code>cons</code>, <code>jac</code>, <code>jprod</code> and <code>jtprod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L94-L98">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S" href="#MultiPrecisionR2.umpt!-Union{Tuple{S}, Tuple{Tuple, Vector{S}}} where S"><code>MultiPrecisionR2.umpt!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">umpt!(x::Tuple, y::Vector{S})</code></pre><p>Update multi precision containers.  Update is occuring only if precision input vector y is lower or equal to the one of the element of the container (vector) to avoid rounding error due to conversion. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L438-L443">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}" href="#MultiPrecisionR2.update_struct!-Tuple{MPR2Precisions, MPR2Precisions}"><code>MultiPrecisionR2.update_struct!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">update_struct!(str,other_str)</code></pre><p>Update the fields of <code>str</code> with the fields of <code>other_str</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MultiPrecisionR2.jl#L196-L200">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}" href="#MultiPrecisionR2.γfunc_test_error_bound-Tuple{Int64, AbstractFloat, Any}"><code>MultiPrecisionR2.γfunc_test_error_bound</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">γfunc_test_error_bound(n::Int,eps::AbstractFloat,γfunc)</code></pre><p>Tests if γfunc callback provides strictly less than 100% error for dot product error of vector of size the dimension of the problem and the lowest machine epsilon.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L104-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MultiPrecisionR2.γfunc_test_template-Tuple{Any}" href="#MultiPrecisionR2.γfunc_test_template-Tuple{Any}"><code>MultiPrecisionR2.γfunc_test_template</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">γfunc_test_template(γfunc)</code></pre><p>Tests if γfunc callback function is properly implemented. Expected template: γfunc(n::Int,u::Float) -&gt; Float</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/utils.jl#L89-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons(nlp)
neval_cons(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns  turn number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons_lin(nlp)
neval_cons_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns  turn number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_cons_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_cons_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_cons_nln(nlp)
neval_cons_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>cons</code> evaluations. If extra argument T is provided, returns  turn number of <code>cons</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_grad-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_grad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_grad(nlp)
neval_grad(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>grad</code> evaluations. If extra argument T is provided, returns  turn number of <code>grad</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_hess-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_hess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_hess(nlp)
neval_hess(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>hess</code> evaluations. If extra argument T is provided, returns  turn number of <code>hess</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_hprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_hprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_hprod(nlp)
neval_hprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>hprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>hprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac(nlp)
neval_jac(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns  turn number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac_lin(nlp)
neval_jac_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns  turn number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jac_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jac_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jac_nln(nlp)
neval_jac_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jac</code> evaluations. If extra argument T is provided, returns  turn number of <code>jac</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jcon-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jcon</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jcon(nlp)
neval_jcon(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jcon</code> evaluations. If extra argument T is provided, returns  turn number of <code>jcon</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jgrad-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jgrad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jgrad(nlp)
neval_jgrad(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jgrad</code> evaluations. If extra argument T is provided, returns  turn number of <code>jgrad</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jhess-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jhess(nlp)
neval_jhess(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jhess</code> evaluations. If extra argument T is provided, returns  turn number of <code>jhess</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jhprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jhprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jhprod(nlp)
neval_jhprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jhprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jhprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod(nlp)
neval_jprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod_lin(nlp)
neval_jprod_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jprod_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jprod_nln(nlp)
neval_jprod_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod(nlp)
neval_jtprod(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod_lin-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_lin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod_lin(nlp)
neval_jtprod_lin(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_jtprod_nln-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_jtprod_nln</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_jtprod_nln(nlp)
neval_jtprod_nln(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>jtprod</code> evaluations. If extra argument T is provided, returns  turn number of <code>jtprod</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.neval_obj-Tuple{AbstractMPNLPModel}" href="#NLPModels.neval_obj-Tuple{AbstractMPNLPModel}"><code>NLPModels.neval_obj</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">neval_obj(nlp)
neval_obj(nlp,T)</code></pre><p>Get the total number (all FP formats) of <code>obj</code> evaluations. If extra argument T is provided, returns  turn number of <code>obj</code> evaluations for the given FP format T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/MultiPrecisionR2/blob/bb91af50df1f9c185bc493501b69fd7d3257f0dc/src/MPCounters.jl#L52-L58">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Tuesday 1 August 2023 17:45">Tuesday 1 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
